{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "We will try to fit the dataset with a Lasso Regression model. The steps are \n",
    "\n",
    "- Implement the Shooting Algorithm\n",
    " * allow for random or non-random order for the coordinates\n",
    " * allow for initial weights all zero or the corresponding solution to Ridge Regression\n",
    "- Determine a class for the model supporting methods\n",
    " * fit \n",
    " * predict \n",
    " * score\n",
    "- Tune hyperparameters\n",
    " * Search for hyperparameters through trial and error\n",
    " * Use upper bound on hyperparameter with warm start\n",
    "- Plot the distributions of weight on the features \n",
    " * Does Lasso Regression give us sparsity\n",
    "- Threshold the values to compare zero/non-zero against the weights of the target function\n",
    "- Implement Projected Gradient Descent \n",
    " * Compare to Shooting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from load_data import load_problem\n",
    "\n",
    "PICKLE_PATH = 'lasso_data.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "\n",
    "x_train, y_train, x_val, y_val, target_fn, coefs_true, featurize = load_problem(PICKLE_PATH)\n",
    "X_train = featurize(x_train)\n",
    "X_val = featurize(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize training data\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.set_title(\"({0}, {1}) Design Matrix\".format(X_train.shape[0], X_train.shape[1]))\n",
    "ax.set_xlabel(\"Feature Index\")\n",
    "ax.set_ylabel(\"Example Number\")\n",
    "temp = ax.imshow(X_train, cmap=plt.cm.Purples, aspect=\"auto\")\n",
    "plt.colorbar(temp, shrink=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinate Descent for Lasso Regression (Shooting Algorithm)\n",
    "\n",
    "For the shooting algorithm, we need to compute the Lasso Regression objective for the stopping condition. Moreover we need a threshold function at each iteration along with the solution to Ridge Regression for initial weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(a, delta):\n",
    "    ####\n",
    "    # your code goes here\n",
    "    ####\n",
    "    \n",
    "def compute_sum_sqr_loss(X, y, w):\n",
    "    ####\n",
    "    # your code goes here\n",
    "    ####\n",
    "    \n",
    "def compute_lasso_objective(X, y, w, l1_reg=0):\n",
    "    ####\n",
    "    # your code goes here\n",
    "    ####\n",
    "    \n",
    "def get_ridge_solution(X, y, l2_reg):\n",
    "    ####\n",
    "    # your code goes here\n",
    "    ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we should avoid loops in the implementation because we need to run the algorithm repeatedly for hyperparameter tuning.\n",
    "\n",
    "Please see Lecture 4 notes for derivation of shooting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shooting_algorithm(X, y, w0=None, l1_reg = 1., max_num_epochs = 1000, min_obj_decrease=1e-8, random=False):\n",
    "    if w0 is None:\n",
    "        w = np.zeros(X.shape[1])\n",
    "    else:\n",
    "        w = np.copy(w0)\n",
    "    d = X.shape[1]\n",
    "    epoch = 0\n",
    "    obj_val = compute_lasso_objective(X, y, w, l1_reg)\n",
    "    obj_decrease = min_obj_decrease + 1.\n",
    "    while (obj_decrease>min_obj_decrease) and (epoch<max_num_epochs):\n",
    "        obj_old = obj_val\n",
    "        # Cyclic coordinates descent\n",
    "        coordinates = range(d)\n",
    "        # Randomized coordinates descent\n",
    "        if random:\n",
    "            coordinates = np.random.permutation(d)\n",
    "        for j in coordinates:\n",
    "            ####\n",
    "            # your code goes here\n",
    "            ...\n",
    "            ...\n",
    "            ####\n",
    "            \n",
    "        obj_val = compute_lasso_objective(X, y, w, l1_reg)\n",
    "        obj_decrease = obj_old - obj_val\n",
    "        epoch += 1\n",
    "    print(\"Ran for \"+str(epoch)+\" epochs. \" + 'Lowest loss: ' + str(obj_val))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" Lasso regression\"\"\"\n",
    "    def __init__(self, l1_reg=1.0, randomized=False):\n",
    "        if l1_reg < 0:\n",
    "            raise ValueError('Regularization penalty should be at least 0.')\n",
    "        self.l1_reg = l1_reg\n",
    "        self.randomized = randomized\n",
    "\n",
    "\n",
    "    def fit(self, X, y, max_epochs = 1000, coef_init=None):\n",
    "        # convert y to 1-dim array, in case we're given a column vector\n",
    "        y = y.reshape(-1)\n",
    "        if coef_init is None:\n",
    "            coef_init = get_ridge_solution(X,y, self.l1_reg)\n",
    "        \n",
    "        ####\n",
    "        # your code goes here\n",
    "        ...\n",
    "        ...\n",
    "        ####\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"w_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return np.dot(X, self.w_)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        try:\n",
    "            getattr(self, \"w_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return compute_sum_sqr_loss(X, y, self.w_)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare to the `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_our_lasso_with_sklearn(X_train, y_train, l1_reg=1):\n",
    "    \n",
    "    # Fit with sklearn -- need to divide l1_reg by 2*sample size, since they\n",
    "    # use a slightly different objective function.\n",
    "    n = X_train.shape[0]\n",
    "    sklearn_lasso = Lasso(alpha=l1_reg/(2*n), fit_intercept=False, normalize=False)\n",
    "    sklearn_lasso.fit(X_train, y_train)\n",
    "    sklearn_lasso_coefs = sklearn_lasso.coef_\n",
    "    sklearn_lasso_preds = sklearn_lasso.predict(X_train)\n",
    "\n",
    "    # Now run our lasso regression and compare the coefficients to sklearn's\n",
    "    \n",
    "    ####\n",
    "    # your code goes here\n",
    "    ...\n",
    "    ...\n",
    "    ####\n",
    "\n",
    "    # Let's compare differences in predictions\n",
    "    print(\"Hoping this is very close to 0 (predictions): {}\".format( np.mean((sklearn_lasso_preds - lasso_regression_preds)**2)))\n",
    "    # Let's compare differences parameter values\n",
    "    print(\"Hoping this is very close to 0: {}\".format(np.sum((our_coefs - sklearn_lasso_coefs)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoping this is very close to 0:4.6903718660670966e-11\n"
     ]
    }
   ],
   "source": [
    "compare_our_ridge_with_sklearn(X_train, y_train, l2_reg=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search to Tune Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use sklearn to help us do hyperparameter tuning\n",
    "GridSearchCv.fit by default splits the data into training and\n",
    "validation itself; we want to use our own splits, so we need to stack our\n",
    "training and validation sets together, and supply an index\n",
    "(validation_fold) to specify which entries are train and which are\n",
    "validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search_lasso(X_train, y_train, X_val, y_val):\n",
    "    ####\n",
    "    ## your code goes here\n",
    "    ...\n",
    "    ...\n",
    "    ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, results = do_grid_search_ridge(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_l2reg</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.172579</td>\n",
       "      <td>0.006752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.172464</td>\n",
       "      <td>0.006752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.171345</td>\n",
       "      <td>0.006774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.008285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.141887</td>\n",
       "      <td>0.032767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.144566</td>\n",
       "      <td>0.094953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171068</td>\n",
       "      <td>0.197694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.179521</td>\n",
       "      <td>0.216591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.187993</td>\n",
       "      <td>0.233450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.196361</td>\n",
       "      <td>0.248803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.204553</td>\n",
       "      <td>0.262958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.212530</td>\n",
       "      <td>0.276116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.220271</td>\n",
       "      <td>0.288422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_l2reg  mean_test_score  mean_train_score\n",
       "0      0.000001         0.172579          0.006752\n",
       "1      0.000010         0.172464          0.006752\n",
       "2      0.000100         0.171345          0.006774\n",
       "3      0.001000         0.162705          0.008285\n",
       "4      0.010000         0.141887          0.032767\n",
       "5      0.100000         0.144566          0.094953\n",
       "6      1.000000         0.171068          0.197694\n",
       "7      1.300000         0.179521          0.216591\n",
       "8      1.600000         0.187993          0.233450\n",
       "9      1.900000         0.196361          0.248803\n",
       "10     2.200000         0.204553          0.262958\n",
       "11     2.500000         0.212530          0.276116\n",
       "12     2.800000         0.220271          0.288422"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation performance vs regularization parameter\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.grid()\n",
    "ax.set_title(\"Validation Performance vs L1 Regularization\")\n",
    "ax.set_xlabel(\"L1-Penalty Regularization Parameter\")\n",
    "ax.set_ylabel(\"Mean Squared Error\")\n",
    "\n",
    "####\n",
    "## your code goes here\n",
    "...\n",
    "...\n",
    "####\n",
    "\n",
    "ax.text(0.005,0.17,\"Best parameter {0}\".format(grid.best_params_['l1reg']), fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing to the Target Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot prediction functions and compare coefficients for several fits and the target function.\n",
    "\n",
    "\n",
    "Let's create a list of dicts called `pred_fns`. Each dict has a \"name\" key and a\n",
    "\"preds\" key. The value corresponding to the \"preds\" key is an array of\n",
    "predictions corresponding to the input vector x. x_train and y_train are\n",
    "the input and output values for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fns = []\n",
    "x = np.sort(np.concatenate([np.arange(0,1,.001), x_train]))\n",
    "\n",
    "pred_fns.append({\"name\": \"Target Function\", \"coefs\": coefs_true, \"preds\": target_fn(x)})\n",
    "\n",
    "l1regs = [0.1, grid.best_params_['l1reg'], 1]\n",
    "X = featurize(x)\n",
    "for l1reg in l1regs:\n",
    "    lasso_regression_estimator = LassoRegression(l1reg=l1reg)\n",
    "    lasso_regression_estimator.fit(X_train, y_train)\n",
    "    name = \"Lasso with L1Reg=\"+str(l1reg)\n",
    "\n",
    "    ####\n",
    "    ## your code goes here\n",
    "    ...\n",
    "    ...\n",
    "    ####    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_functions(x, pred_fns, x_train, y_train, legend_loc=\"best\"):\n",
    "\n",
    "\tfig, ax = plt.subplots(figsize = (12,8))\n",
    "\tax.set_xlabel('Input Space: [0,1)')\n",
    "\tax.set_ylabel('Action/Outcome Space')\n",
    "\tax.set_title(\"Prediction Functions\")\n",
    "\tplt.scatter(x_train, y_train, color=\"k\", label='Training data')\n",
    "\tfor i in range(len(pred_fns)):\n",
    "\t\tax.plot(x, pred_fns[i][\"preds\"], label=pred_fns[i][\"name\"])\n",
    "\tlegend = ax.legend(loc=legend_loc, shadow=True)\n",
    "\treturn fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_functions(x, pred_fns, x_train, y_train, legend_loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Weights\n",
    "\n",
    "Using `pred_fns` let's try to see how sparse the weights are... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_parameter_vectors(pred_fns):\n",
    "\n",
    "\tfig, axs = plt.subplots(len(pred_fns),1, sharex=True, figsize = (20,20))\n",
    "\tnum_ftrs = len(pred_fns[0][\"coefs\"])\n",
    "\tfor i in range(len(pred_fns)):\n",
    "\t\ttitle = pred_fns[i][\"name\"]\n",
    "\t\tcoef_vals = pred_fns[i][\"coefs\"]\n",
    "\t\taxs[i].bar(range(num_ftrs), coef_vals, color = \"tab:purple\")\n",
    "\t\taxs[i].set_xlabel('Feature Index')\n",
    "\t\taxs[i].set_ylabel('Parameter Value')\n",
    "\t\taxs[i].set_title(title)\n",
    "\n",
    "\tfig.subplots_adjust(hspace=0.4)\n",
    "\treturn fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_parameter_vectors(pred_fns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the largest value of $\\lambda$ for which the weights can be nonzero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda_max_no_bias(X, y):\n",
    "    return 2 * np.max(np.abs(np.dot(y, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use homotopy method to compute regularization path for LassoRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegularizationPath:\n",
    "    def __init__(self, estimator, tune_param_name):\n",
    "        self.estimator = estimator\n",
    "        self.tune_param_name = tune_param_name\n",
    "\n",
    "    def fit(self, X, y, reg_vals, coef_init=None, warm_start=True):\n",
    "        # reg_vals is a list of regularization parameter values to solve for.\n",
    "        # Solutions will be found in the order given by reg_vals.\n",
    "\n",
    "        #convert y to 1-dim array, in case we're given a column vector\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        if coef_init is not None:\n",
    "            coef_init = np.copy(coef_init)\n",
    "\n",
    "        self.results = []\n",
    "        for reg_val in reg_vals:\n",
    "            estimator = clone(self.estimator)\n",
    "\n",
    "            ####\n",
    "            ## your code goes here\n",
    "            ...\n",
    "            ...\n",
    "            ####\n",
    "            \n",
    "            self.results.append({\"reg_val\":reg_val, \"estimator\":estimator})\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        predictions = []\n",
    "        for i in range(len(self.results)):\n",
    "            preds = self.results[i][\"estimator\"].predict(X)\n",
    "            reg_val = self.results[i][\"reg_val\"]\n",
    "            predictions.append({\"reg_val\":reg_val, \"preds\":preds})\n",
    "        return predictions\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        scores = []\n",
    "        for i in range(len(self.results)):\n",
    "            score = self.results[i][\"estimator\"].score(X, y)\n",
    "            reg_val = self.results[i][\"reg_val\"]\n",
    "            scores.append({\"reg_val\":reg_val, \"score\":score})\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search_homotopy(X_train, y_train, X_val, y_val,\n",
    "                            reg_vals=None, w0=None):\n",
    "    if reg_vals is None:\n",
    "        lambda_max = get_lambda_max_no_bias(X_train, y_train)\n",
    "        reg_vals = [lambda_max * (.8**n) for n in range(0, 30)]\n",
    "    \n",
    "    ####\n",
    "    ## your code goes here\n",
    "    ...\n",
    "    ...\n",
    "    ####\n",
    "    \n",
    "    estimator = LassoRegression()\n",
    "    lasso_reg_path_estimator = LassoRegularizationPath(estimator, tune_param_name=\"l1_reg\")\n",
    "    lasso_reg_path_estimator.fit(X_train, y_train,\n",
    "                                 reg_vals=reg_vals[:], coef_init=w0,\n",
    "                                 warm_start=True)\n",
    "    \n",
    "    return lasso_reg_path_estimator, reg_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg_path_estimator, reg_vals = do_grid_search_homotopy(X_train, \n",
    "                                                             y_train, \n",
    "                                                             X_val, \n",
    "                                                             y_val, \n",
    "                                                             None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projected SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_SGD_split(X, y, theta_positive_0, theta_negative_0, lambda_reg = 1.0, alpha = 0.1, num_iter = 1000):\n",
    "    m, n = X.shape\n",
    "    theta_positive = np.zeros(n)\n",
    "    theta_negative = np.zeros(n)\n",
    "    theta_positive[0:n] = theta_positive_0\n",
    "    theta_negative[0:n] = theta_negative_0\n",
    "    times = 0\n",
    "    theta = theta_positive - theta_negative\n",
    "    loss = compute_sum_sqr_loss(X, y, theta)\n",
    "    loss_change = 1.\n",
    "    while (loss_change>1e-6) and (times<num_iter):\n",
    "        loss_old = loss\n",
    "        for i in range(m):\n",
    "            ####\n",
    "            ## your code goes here\n",
    "            ...\n",
    "            ...\n",
    "            ####\n",
    "        loss = compute_sum_sqr_loss(X, y, theta)\n",
    "        loss_change = np.abs(loss - loss_old)\n",
    "        times +=1\n",
    "\n",
    "    print('(SGD) Ran for {} epochs. Loss:{} Lambda: {}'.format(times,loss,lambda_reg))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training, y_training, x_validation, y_validation, target_fn, coefs_true, featurize = load_problem(PICKLE_PATH)\n",
    "X_training = featurize(x_training)\n",
    "X_validation = featurize(x_validation)\n",
    "D = X_training.shape[1]\n",
    "\n",
    "lambda_max = get_lambda_max_no_bias(x_training, y_training)\n",
    "reg_vals = [lambda_max * (.6**n) for n in range(15, 25)]\n",
    "\n",
    "loss_SGD_list = []\n",
    "loss_shooting = []\n",
    "loss_GD_list = []\n",
    "    \n",
    "for lambda_value in reg_vals:\n",
    "    ####\n",
    "    ## your code goes here\n",
    "    ...\n",
    "    ...\n",
    "    ####   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation performance vs regularization parameter\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.grid()\n",
    "ax.set_title(\"Validation Performance vs L1 Regularization\")\n",
    "ax.set_xlabel(\"L1-Penalty Regularization Parameter\")\n",
    "ax.set_ylabel(\"Mean Squared Error\")\n",
    "\n",
    "plt.semilogx(reg_vals, loss_shooting, label = 'Shooting Method')\n",
    "plt.semilogx(reg_vals, loss_SGD_list, label = 'Projection SGD')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the best \n",
    "\n",
    "lambda_best_SGD = reg_vals[np.argmin(loss_SGD_list)]\n",
    "theta_lasso_SGD_best = projection_SGD_split(X_training, y_training, theta_positive_ini, theta_negative_ini, lambda_reg=lambda_best_SGD, alpha = 0.01)\n",
    "print('Best lambda for SGD is {0} with loss {1}'.format(lambda_best_SGD, np.min(loss_SGD_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
