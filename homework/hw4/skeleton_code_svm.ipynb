{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from load import *\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data():\n",
    "    '''\n",
    "    Description\n",
    "    ===========\n",
    "    - Load positive / negative reviews\n",
    "    - Combine datasets\n",
    "    - Randomly permute entries\n",
    "    '''\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reviewInstance:\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ===========\n",
    "    Tranform text in review to sparse encoding of words \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,word_list):\n",
    "    \"\"\"\n",
    "    Description \n",
    "    ===========\n",
    "    - Construtor requires list of words\n",
    "    - Processing in load.read_data\n",
    "    \"\"\"    \n",
    "        \n",
    "    def construct_word_dict(self, stop_word=None, count_words=None):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ===========\n",
    "        Count words in word_list to transform to a dict {word: word_count}\n",
    "        \n",
    "        Input\n",
    "        =====\n",
    "        stop_word: list\n",
    "        Words you hope to filter, not included in dict, default set to None\n",
    "        \n",
    "        count_words: list\n",
    "        Words you hope to keep in the count_dict, if set to None, will keep all the words\n",
    "        \"\"\"\n",
    "        \n",
    "    def transform_to_tfidf(self, idf_dict):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ===========\n",
    "        Construct the {word: tfidf} vector tfidf\n",
    "        \n",
    "        Input\n",
    "        =====\n",
    "        Document frequency for each word\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_sgd_loss(review_X, review_y, w, reg_lambda):\n",
    "    \"\"\" Implementation of Objective Function\"\"\"\n",
    "    \n",
    "def pegasos_sgd_gradient(review_X, review_y, w, reg_lambda):\n",
    "    \"\"\" Implementation of Gradient of Objective Function\"\"\"\n",
    "    \n",
    "    \n",
    "def gradient_checker_for_pegasos(review_X, review_y, weight, reg_lambda, objective_func=pegasos_sgd_loss,\n",
    "                                 gradient_func=pegasos_sgd_gradient, epsilon=0.01, tolerance=1e-4):\n",
    "    \"\"\" Gradient Checker adapted from Homework 1 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_percent(review_list, weight, tfidf=False):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ===========\n",
    "    Accuracy of predictions for collection of reviews under weights\n",
    "    \"\"\"\n",
    "\n",
    "def magnitude_compare(review_list, weight):\n",
    "    \"\"\"\n",
    "    Description \n",
    "    ==========\n",
    "    Generate scatter-plot showing positive / negative predictions\n",
    "    for positive labels and positive / negative predictions for \n",
    "    negative labels\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(review_list, max_epoch, lam, watch_list=None, grad_checking=False):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ==========\n",
    "    Implementation of Pegasos Algorithm \n",
    "\n",
    "    Input\n",
    "    =====\n",
    "    review_list: list of reviewInstance's\n",
    "    list of objects with labels and encoded input from reviews\n",
    "\n",
    "    max_epoch: int \n",
    "    stopping condition\n",
    "\n",
    "    lam: float \n",
    "    regularization parameter\n",
    "\n",
    "    watch_list: list or reviewInstance's\n",
    "    passed to accuracy_percent or magnitude_compare; default None\n",
    "\n",
    "    grad_checking: bool \n",
    "    numerical test of gradient of svm objective\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    weights\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialization\n",
    "    weight = Counter()\n",
    "    epoch = 0\n",
    "    t = 0.\n",
    "    review_number = len(review_list)\n",
    "    weight_grad=Counter()\n",
    "\n",
    "    #Loop\n",
    "    # Use the util.increment and util.dotProduct functions in update\n",
    "    while epoch < max_epoch:\n",
    "        \n",
    "        ...\n",
    "        \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_fast(review_list, max_epoch, lam, watch_list=None, grad_checking=False, tfidf= False):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ==========\n",
    "    Implementation of Pegasos Algorithm \n",
    "\n",
    "    Input\n",
    "    =====\n",
    "    review_list: list of reviewInstance's\n",
    "    list of objects with labels and encoded input from reviews\n",
    "\n",
    "    max_epoch: int \n",
    "    stopping condition\n",
    "\n",
    "    lam: float \n",
    "    regularization parameter\n",
    "\n",
    "    watch_list: list or reviewInstance's\n",
    "    passed to accuracy_percent or magnitude_compare; default None\n",
    "\n",
    "    grad_checking: bool \n",
    "    numerical test of gradient of svm objective\n",
    "    \n",
    "    tfidf: bool\n",
    "    use tf-idf encoding of text in review_list\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    weights\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialization\n",
    "    weight = Counter()\n",
    "    epoch = 0\n",
    "    t = 1.\n",
    "    review_number = len(review_list)\n",
    "    s = 1.\n",
    "\n",
    "    #Loop\n",
    "    # Use the util.increment and util.dotProduct functions in update\n",
    "    while epoch < max_epoch:\n",
    "          \n",
    "        ...\n",
    "\n",
    "    return epoch_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(review_X, weight):\n",
    "    if dotProduct(weight, review_X)>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print (\"Loading data\")\n",
    "    review_list= shuffle_data()\n",
    "\n",
    "    print (\"Train validation split\")\n",
    "    train_review = list(map(reviewInstance,review_list[:1500]))\n",
    "    validate_review = list(map(reviewInstance,review_list[1500:]))\n",
    "\n",
    "    print (\"Build the corpus to get idf\")\n",
    "\n",
    "    train_label = np.array([i.label for i in train_review])\n",
    "    validate_label = np.array([i.label for i in validate_review])\n",
    "\n",
    "    print (\"In training: %r positive, %r negative\" %(np.sum(train_label[train_label>0]), -np.sum(train_label[train_label<0])))\n",
    "    print (\"In validation: %r positive, %r negative\" %(np.sum(validate_label[validate_label>0]), -np.sum(validate_label[validate_label<0])))\n",
    "\n",
    "    w = pegasos_fast(train_review, 20, 1.0, watch_list=validate_review, tfidf= False)\n",
    "\n",
    "    magnitude_compare(validate_review, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
